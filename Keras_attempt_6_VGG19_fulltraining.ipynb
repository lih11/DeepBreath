{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.applications import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\") # set the matplotlib backend so figures can be saved in the background\n",
    " \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from time import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191229, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No Finding</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.088899</td>\n",
       "      <td>0.284598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.102380</td>\n",
       "      <td>0.303148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.157706</td>\n",
       "      <td>0.364466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Opacity</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.516444</td>\n",
       "      <td>0.499731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Lesion</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>0.201985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.321787</td>\n",
       "      <td>0.467163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consolidation</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>0.396629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.108059</td>\n",
       "      <td>0.310456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atelectasis</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.311972</td>\n",
       "      <td>0.463299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.106720</td>\n",
       "      <td>0.308758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.452552</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Other</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.148561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fracture</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.041495</td>\n",
       "      <td>0.199432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Devices</th>\n",
       "      <td>191229.0</td>\n",
       "      <td>0.565730</td>\n",
       "      <td>0.495662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count      mean       std  min  25%  50%  75%  \\\n",
       "No Finding                  191229.0  0.088899  0.284598  0.0  0.0  0.0  0.0   \n",
       "Enlarged Cardiomediastinum  191229.0  0.102380  0.303148  0.0  0.0  0.0  0.0   \n",
       "Cardiomegaly                191229.0  0.157706  0.364466  0.0  0.0  0.0  0.0   \n",
       "Lung Opacity                191229.0  0.516444  0.499731  0.0  0.0  1.0  1.0   \n",
       "Lung Lesion                 191229.0  0.042614  0.201985  0.0  0.0  0.0  0.0   \n",
       "Edema                       191229.0  0.321787  0.467163  0.0  0.0  0.0  1.0   \n",
       "Consolidation               191229.0  0.195556  0.396629  0.0  0.0  0.0  0.0   \n",
       "Pneumonia                   191229.0  0.108059  0.310456  0.0  0.0  0.0  0.0   \n",
       "Atelectasis                 191229.0  0.311972  0.463299  0.0  0.0  0.0  1.0   \n",
       "Pneumothorax                191229.0  0.106720  0.308758  0.0  0.0  0.0  0.0   \n",
       "Pleural Effusion            191229.0  0.452552  0.497745  0.0  0.0  0.0  1.0   \n",
       "Pleural Other               191229.0  0.022580  0.148561  0.0  0.0  0.0  0.0   \n",
       "Fracture                    191229.0  0.041495  0.199432  0.0  0.0  0.0  0.0   \n",
       "Support Devices             191229.0  0.565730  0.495662  0.0  0.0  1.0  1.0   \n",
       "\n",
       "                            max  \n",
       "No Finding                  1.0  \n",
       "Enlarged Cardiomediastinum  1.0  \n",
       "Cardiomegaly                1.0  \n",
       "Lung Opacity                1.0  \n",
       "Lung Lesion                 1.0  \n",
       "Edema                       1.0  \n",
       "Consolidation               1.0  \n",
       "Pneumonia                   1.0  \n",
       "Atelectasis                 1.0  \n",
       "Pneumothorax                1.0  \n",
       "Pleural Effusion            1.0  \n",
       "Pleural Other               1.0  \n",
       "Fracture                    1.0  \n",
       "Support Devices             1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathFileTrain = \"CheXpert-v1.0-small/train.csv\"\n",
    "pathFileValid = \"CheXpert-v1.0-small/valid.csv\"\n",
    "\n",
    "# import train data from train.csv into panda struct\n",
    "dtrain = pd.read_csv(pathFileTrain)\n",
    "# fill in blanks with 0s\n",
    "dtrain = dtrain.fillna(0)\n",
    "\n",
    "# import valid data from valid.csv into panda struct\n",
    "dvalid = pd.read_csv(pathFileValid)\n",
    "# fill in blanks with 0s\n",
    "dvalid = dvalid.fillna(0)\n",
    "\n",
    "# combine train and valid dataset\n",
    "dtrain = dtrain.append(dvalid)\n",
    "\n",
    "# remove lateral images\n",
    "dtrain = dtrain[~dtrain[dtrain.columns[3]].str.contains(\"Lateral\")]\n",
    "\n",
    "# drop the columns for sex, age, frontal/lateral, and AP/PA\n",
    "dtrain = dtrain.drop([\"Sex\", \"Age\", \"Frontal/Lateral\", \"AP/PA\"], axis=1)\n",
    "\n",
    "# convert uncertain to positive (-1 to 1)\n",
    "dtrain = dtrain.replace(-1,1)\n",
    "\n",
    "print(dtrain.shape)\n",
    "dtrain.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191229\n",
      "152983\n",
      "19123\n",
      "19123\n",
      "152983\n",
      "19123\n",
      "19123\n"
     ]
    }
   ],
   "source": [
    "# Split data into train/dev/test 0.8/0.1/0.1\n",
    "\n",
    "# Randomize the data\n",
    "dtotal = dtrain.sample(frac=1)\n",
    "\n",
    "# Split data into traing (80%), valid (10%) and test (10%)\n",
    "dvalid_size = round(0.1*dtotal.shape[0])\n",
    "dtest_size = dvalid_size\n",
    "dtrain_size = dtotal.shape[0] - dvalid_size - dtest_size\n",
    "\n",
    "x_train = dtotal[0:dtrain_size]\n",
    "x_valid = dtotal[dtrain_size:dtrain_size+dvalid_size]\n",
    "x_test = dtotal[dtrain_size+dvalid_size:dtotal.shape[0]+1]\n",
    "\n",
    "\n",
    "print(\"The total number of data is:\", dtotal.shape[0])\n",
    "\n",
    "print(\"The size of training set is:\", x_train.shape[0])\n",
    "print(\"The size of the dev set is:\", x_valid.shape[0])\n",
    "print(\"The size of the test set is:\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152983 validated image filenames.\n",
      "Found 19123 validated image filenames.\n",
      "Found 19123 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Data generation \n",
    "# https://keras.io/preprocessing/image/#imagedatagenerator-class\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "target_size = (224, 224)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe = x_train,\n",
    "        directory = None,\n",
    "        x_col = \"Path\",\n",
    "        y_col = list(x_train.columns[1:15]),\n",
    "        class_mode = \"other\",\n",
    "        target_size = target_size,\n",
    "        batch_size = 32)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "        dataframe = x_valid,\n",
    "        directory = None,\n",
    "        x_col = \"Path\",\n",
    "        y_col = list(x_valid.columns[1:15]),\n",
    "        class_mode = \"other\",\n",
    "        target_size = target_size,\n",
    "        batch_size = 32)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe = x_test,\n",
    "        directory = None,\n",
    "        x_col = \"Path\",\n",
    "        y_col = list(x_test.columns[1:15]),\n",
    "        class_mode = \"other\",\n",
    "        target_size = target_size,\n",
    "        batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the model architecture\n",
    "# Use the VGG19 model with pretrained weights from imagenet. Exclude the top layers.\n",
    "model = VGG19(include_top = False, weights='imagenet')\n",
    "layer1 = model.output\n",
    "# adding a 2D pooling layer\n",
    "layer1 = GlobalAveragePooling2D()(layer1)\n",
    "# adding a fully connected layer\n",
    "layer1 = Dense(1024, activation='relu')(layer1)\n",
    "# adding a softmax layer\n",
    "predictions = Dense(14, activation='sigmoid')(layer1)\n",
    "\n",
    "Model_VGG19 = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                14350     \n",
      "=================================================================\n",
      "Total params: 20,564,046\n",
      "Trainable params: 20,564,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Use Adam optimization\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "Model_VGG19.compile(optimizer= adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(Model_VGG19.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4780/4780 [==============================] - 4796s 1s/step - loss: 0.3786 - acc: 0.8329 - val_loss: 0.3603 - val_acc: 0.8438\n",
      "Epoch 2/3\n",
      "4780/4780 [==============================] - 4778s 1000ms/step - loss: 0.3563 - acc: 0.8446 - val_loss: 0.3530 - val_acc: 0.8471\n",
      "Epoch 3/3\n",
      "4780/4780 [==============================] - 4765s 997ms/step - loss: 0.3469 - acc: 0.8492 - val_loss: 0.3469 - val_acc: 0.8498\n"
     ]
    }
   ],
   "source": [
    "# Fitting data into the model architecture\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "FullModel = Model_VGG19.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=num_epochs)\n",
    "\n",
    "# Save the model!\n",
    "Model_VGG19.save(\"Model_VGG19_frac=001_epoch=3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss curve\n",
    "plt.plot(FullModel.history['loss'])\n",
    "plt.plot(FullModel.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(\"losscurve_attempt6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_VGG = load_model('Model_VGG19_frac=001_epoch=3.h5')\n",
    "num_epochs = 3\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                No Finding       0.11      0.04      0.06      1629\n",
      "Enlarged Cardiomediastinum       0.00      0.00      0.00      1942\n",
      "              Cardiomegaly       0.16      0.09      0.12      3134\n",
      "              Lung Opacity       0.51      0.59      0.55      9931\n",
      "               Lung Lesion       0.00      0.00      0.00       832\n",
      "                     Edema       0.33      0.23      0.27      6229\n",
      "             Consolidation       0.00      0.00      0.00      3633\n",
      "                 Pneumonia       0.17      0.00      0.00      2069\n",
      "               Atelectasis       0.32      0.03      0.06      5952\n",
      "              Pneumothorax       0.12      0.04      0.05      2065\n",
      "          Pleural Effusion       0.46      0.56      0.50      8630\n",
      "             Pleural Other       0.00      0.00      0.00       446\n",
      "                  Fracture       0.00      0.00      0.00       813\n",
      "           Support Devices       0.58      0.65      0.61     10971\n",
      "\n",
      "                 micro avg       0.47      0.34      0.39     58276\n",
      "                 macro avg       0.20      0.16      0.16     58276\n",
      "              weighted avg       0.35      0.34      0.33     58276\n",
      "               samples avg       0.42      0.32      0.33     58276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Assess performance\n",
    "test_generator.reset()\n",
    "pred = model_VGG.predict_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "pred_bool = (pred >= 0.5)\n",
    "\n",
    "y_pred = np.array(pred_bool,dtype =int)\n",
    "\n",
    "dtest = x_test.to_numpy()\n",
    "y_true = np.array(dtest[:,1:15],dtype=int)\n",
    "\n",
    "print(classification_report(y_true, y_pred,target_names=list(x_train.columns[1:15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.34925117049233184\n",
      "Test accuracy: 0.8487049940100202\n"
     ]
    }
   ],
   "source": [
    "# Generate score and accuracy\n",
    "score, accuracy = model_VGG.evaluate_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
